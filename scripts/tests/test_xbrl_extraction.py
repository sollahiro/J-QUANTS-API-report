"""
XBRLã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã™ã‚‹ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ

EDINETã‹ã‚‰XBRLã‚’å–å¾—ã—ã€ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã—ã¦è¡¨å½¢å¼ãƒ‡ãƒ¼ã‚¿ã‚’é™¤å¤–ã—ã¾ã™ã€‚
"""

import sys
import re
import xml.etree.ElementTree as ET
from pathlib import Path
from typing import Optional, Set

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from src.api.edinet_client import EdinetAPIClient
from src.api.client import JQuantsAPIClient
from src.config import config


class XBRLParser:
    """XBRLã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã™ã‚‹ãƒ‘ãƒ¼ã‚µãƒ¼"""
    
    # è¡¨ã‚¿ã‚°ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆé™¤å¤–å¯¾è±¡ï¼‰
    TABLE_TAGS = {
        'table', 'table:table', 'table:tableGroup', 'table:tableModel',
        'table:tableHeader', 'table:tableBody', 'table:tableFooter',
        'table:tableRow', 'table:tableCell', 'table:tableContent',
        'ix:table', 'ix:tableGroup', 'ix:tableHeader', 'ix:tableBody',
        'ix:tableRow', 'ix:tableCell'
    }
    
    # ãƒ†ã‚­ã‚¹ãƒˆã‚’å«ã‚€å¯èƒ½æ€§ã®ã‚ã‚‹ã‚¿ã‚°
    TEXT_TAGS = {
        'p', 'paragraph', 'text', 'content', 'description',
        'note', 'footnote', 'narrative', 'textBlock',
        'ix:nonNumeric', 'ix:nonFraction', 'ix:text',
        'jpcrp_cor:BusinessPolicyTextBlock',
        'jpcrp_cor:BusinessRisksTextBlock',
        'jpcrp_cor:BusinessResultsOfOperationsTextBlock',
        'jpcrp_cor:ManagementAnalysisOfFinancialPositionOperatingResultsAndCashFlowsTextBlock',
        'jpcrp_cor:BasicPolicyRegardingProfitDistributionAndReturnOfSurplusTextBlock',
    }
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        self.namespaces = {}
    
    def _register_namespaces(self, root: ET.Element):
        """XMLåå‰ç©ºé–“ã‚’ç™»éŒ²"""
        for prefix, uri in root.attrib.items():
            if prefix.startswith('xmlns'):
                if prefix == 'xmlns':
                    self.namespaces[''] = uri
                else:
                    ns_prefix = prefix.replace('xmlns:', '')
                    self.namespaces[ns_prefix] = uri
    
    def _extract_text_from_html(self, element: ET.Element) -> str:
        """HTMLã‚¿ã‚°ã‚’å«ã‚€è¦ç´ ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºï¼ˆè¡¨ã‚’é™¤å¤–ï¼‰"""
        import html
        
        # è¦ç´ ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
        text_parts = []
        
        # è¦ç´ ã®ç›´æ¥ã®ãƒ†ã‚­ã‚¹ãƒˆ
        if element.text:
            text = element.text.strip()
            if text:
                text_parts.append(text)
        
        # å­è¦ç´ ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’å†å¸°çš„ã«æŠ½å‡º
        for child in element:
            # è¡¨è¦ç´ ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
            if self._is_table_element(child):
                continue
            
            child_text = self._extract_text_from_html(child)
            if child_text:
                text_parts.append(child_text)
            
            # å­è¦ç´ ã®å¾Œã®ãƒ†ã‚­ã‚¹ãƒˆï¼ˆtailï¼‰
            if child.tail:
                tail_text = child.tail.strip()
                if tail_text:
                    text_parts.append(tail_text)
        
        combined_text = '\n'.join(text_parts)
        
        # HTMLã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã‚’ãƒ‡ã‚³ãƒ¼ãƒ‰
        combined_text = html.unescape(combined_text)
        
        # HTMLã‚¿ã‚°ã‚’é™¤å»ï¼ˆæ­£è¦è¡¨ç¾ã§ï¼‰
        combined_text = re.sub(r'<[^>]+>', '', combined_text)
        
        # ä½™åˆ†ãªç©ºç™½ã‚’æ•´ç†
        combined_text = re.sub(r'\s+', ' ', combined_text)
        combined_text = combined_text.strip()
        
        return combined_text
    
    def _is_table_element(self, element: ET.Element) -> bool:
        """è¦ç´ ãŒè¡¨è¦ç´ ã‹ã©ã†ã‹ã‚’åˆ¤å®š"""
        tag = element.tag
        # åå‰ç©ºé–“ã‚’é™¤å»ã—ãŸã‚¿ã‚°åã‚’å–å¾—
        if '}' in tag:
            tag = tag.split('}')[1]
        
        # è¡¨ã‚¿ã‚°ã‹ã©ã†ã‹ãƒã‚§ãƒƒã‚¯
        if tag in self.TABLE_TAGS:
            return True
        
        # å±æ€§ã§åˆ¤å®š
        if element.get('class') and 'table' in element.get('class', '').lower():
            return True
        
        return False
    
    def _is_text_block(self, element: ET.Element) -> bool:
        """è¦ç´ ãŒãƒ†ã‚­ã‚¹ãƒˆãƒ–ãƒ­ãƒƒã‚¯ã‹ã©ã†ã‹ã‚’åˆ¤å®š"""
        tag = element.tag
        # åå‰ç©ºé–“ã‚’é™¤å»ã—ãŸã‚¿ã‚°åã‚’å–å¾—
        if '}' in tag:
            tag = tag.split('}')[1]
        
        # TextBlockã§çµ‚ã‚ã‚‹ã‚¿ã‚°ã¯ãƒ†ã‚­ã‚¹ãƒˆãƒ–ãƒ­ãƒƒã‚¯
        if tag.endswith('TextBlock') or 'TextBlock' in tag:
            return True
        
        # ç‰¹å®šã®ãƒ†ã‚­ã‚¹ãƒˆãƒ–ãƒ­ãƒƒã‚¯ã‚¿ã‚°ã‚’ãƒã‚§ãƒƒã‚¯
        text_block_patterns = [
            'BusinessPolicyTextBlock',
            'BusinessRisksTextBlock',
            'BusinessResultsOfOperationsTextBlock',
            'ManagementAnalysisOfFinancialPositionOperatingResultsAndCashFlowsTextBlock',
            'BasicPolicyRegardingProfitDistributionAndReturnOfSurplusTextBlock',
            'DescriptionOfBusinessTextBlock',
            'OverviewOfBusinessResultsTextBlock',
            'AnalysisOfFinancialPositionOperatingResultsAndCashFlowsTextBlock',
        ]
        
        for pattern in text_block_patterns:
            if pattern in tag:
                return True
        
        return False
    
    def _extract_text_from_element(self, element: ET.Element, exclude_tables: bool = True, in_text_block: bool = False) -> str:
        """è¦ç´ ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºï¼ˆè¡¨ã‚’é™¤å¤–ï¼‰"""
        # è¡¨è¦ç´ ã®å ´åˆã¯ç©ºæ–‡å­—åˆ—ã‚’è¿”ã™
        if exclude_tables and self._is_table_element(element):
            return ""
        
        # ãƒ†ã‚­ã‚¹ãƒˆãƒ–ãƒ­ãƒƒã‚¯ã®é–‹å§‹ã‚’æ¤œå‡º
        is_text_block = self._is_text_block(element)
        if is_text_block:
            in_text_block = True
        
        texts = []
        
        # ãƒ†ã‚­ã‚¹ãƒˆãƒ–ãƒ­ãƒƒã‚¯å†…ã®å ´åˆã€ã¾ãŸã¯ãƒ†ã‚­ã‚¹ãƒˆãƒ–ãƒ­ãƒƒã‚¯è¦ç´ è‡ªä½“ã®å ´åˆ
        if in_text_block or is_text_block:
            # è¦ç´ ã®ç›´æ¥ã®ãƒ†ã‚­ã‚¹ãƒˆ
            if element.text:
                text = element.text.strip()
                if text and len(text) > 10:  # çŸ­ã™ãã‚‹ãƒ†ã‚­ã‚¹ãƒˆã¯é™¤å¤–
                    texts.append(text)
        
        # å­è¦ç´ ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’å†å¸°çš„ã«æŠ½å‡º
        for child in element:
            child_text = self._extract_text_from_element(child, exclude_tables, in_text_block)
            if child_text:
                texts.append(child_text)
            
            # å­è¦ç´ ã®å¾Œã®ãƒ†ã‚­ã‚¹ãƒˆï¼ˆtailï¼‰
            if child.tail and (in_text_block or is_text_block):
                tail_text = child.tail.strip()
                if tail_text and len(tail_text) > 10:
                    texts.append(tail_text)
        
        return '\n'.join(texts)
    
    def extract_text_from_xbrl(self, xbrl_dir: Path, exclude_tables: bool = True) -> str:
        """
        XBRLãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º
        
        Args:
            xbrl_dir: XBRLãŒå±•é–‹ã•ã‚ŒãŸãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            exclude_tables: è¡¨ã‚’é™¤å¤–ã™ã‚‹ã‹ã©ã†ã‹
            
        Returns:
            æŠ½å‡ºã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ
        """
        all_texts = []
        
        # XBRLã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹æ–‡æ›¸ã‚’æ¤œç´¢ï¼ˆ.xbrlãƒ•ã‚¡ã‚¤ãƒ«ã€ã¾ãŸã¯lab/pre/cal/defä»¥å¤–ã®XMLãƒ•ã‚¡ã‚¤ãƒ«ï¼‰
        xml_files = []
        for xml_file in xbrl_dir.rglob("*.xml"):
            # ãƒ©ãƒ™ãƒ«ã€ãƒ—ãƒ¬ã‚¼ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã€è¨ˆç®—ã€å®šç¾©ãƒ•ã‚¡ã‚¤ãƒ«ã¯é™¤å¤–
            if any(suffix in xml_file.name for suffix in ['_lab.xml', '_pre.xml', '_cal.xml', '_def.xml']):
                continue
            xml_files.append(xml_file)
        
        # .xbrlãƒ•ã‚¡ã‚¤ãƒ«ã‚‚æ¤œç´¢
        xbrl_files = list(xbrl_dir.rglob("*.xbrl"))
        xml_files.extend(xbrl_files)
        
        if not xml_files:
            print(f"âš ï¸ XBRLã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹æ–‡æ›¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {xbrl_dir}")
            return ""
        
        print(f"ğŸ“„ {len(xml_files)}å€‹ã®XBRLã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹æ–‡æ›¸ã‚’å‡¦ç†ä¸­...")
        
        for xml_file in xml_files:
            try:
                # XMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‘ãƒ¼ã‚¹
                tree = ET.parse(xml_file)
                root = tree.getroot()
                
                # åå‰ç©ºé–“ã‚’ç™»éŒ²
                self._register_namespaces(root)
                
                # ãƒ†ã‚­ã‚¹ãƒˆãƒ–ãƒ­ãƒƒã‚¯è¦ç´ ã‚’æ¤œç´¢ï¼ˆTextBlockã§çµ‚ã‚ã‚‹è¦ç´ ï¼‰
                text_blocks = []
                
                # å…¨ã¦ã®è¦ç´ ã‚’èµ°æŸ»ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆãƒ–ãƒ­ãƒƒã‚¯ã‚’æ¤œç´¢
                for elem in root.iter():
                    tag = elem.tag
                    # åå‰ç©ºé–“ã‚’é™¤å»
                    if '}' in tag:
                        tag = tag.split('}')[1]
                    
                    # TextBlockã§çµ‚ã‚ã‚‹è¦ç´ ã‚’æ¤œç´¢
                    if tag.endswith('TextBlock') or 'TextBlock' in tag:
                        # è¦ç´ ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—ï¼ˆHTMLã‚¿ã‚°ã‚’é™¤å»ï¼‰
                        text = self._extract_text_from_html(elem)
                        if text and len(text) > 50:  # 50æ–‡å­—ä»¥ä¸Šã®ãƒ†ã‚­ã‚¹ãƒˆãƒ–ãƒ­ãƒƒã‚¯ã®ã¿
                            text_blocks.append(text)
                
                if text_blocks:
                    combined_text = '\n\n'.join(text_blocks)
                    all_texts.append(combined_text)
                    print(f"  âœ… {xml_file.name}: {len(combined_text)}æ–‡å­— ({len(text_blocks)}å€‹ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ–ãƒ­ãƒƒã‚¯)")
                else:
                    print(f"  âš ï¸ {xml_file.name}: ãƒ†ã‚­ã‚¹ãƒˆãƒ–ãƒ­ãƒƒã‚¯ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            
            except ET.ParseError as e:
                print(f"  âš ï¸ XMLãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {xml_file.name} - {e}")
                continue
            except Exception as e:
                print(f"  âš ï¸ ã‚¨ãƒ©ãƒ¼: {xml_file.name} - {e}")
                continue
        
        combined_text = '\n\n'.join(all_texts)
        
        # è¡¨å½¢å¼ãƒ‡ãƒ¼ã‚¿ã‚’é™¤å¤–ï¼ˆæ­£è¦è¡¨ç¾ãƒ™ãƒ¼ã‚¹ï¼‰
        if exclude_tables:
            combined_text = self._filter_table_data(combined_text)
        
        return combined_text
    
    def _filter_table_data(self, text: str) -> str:
        """
        è¡¨å½¢å¼ã®ãƒ‡ãƒ¼ã‚¿ã‚’é™¤å¤–ï¼ˆæ­£è¦è¡¨ç¾ãƒ™ãƒ¼ã‚¹ï¼‰
        
        Args:
            text: å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆ
            
        Returns:
            è¡¨å½¢å¼ãƒ‡ãƒ¼ã‚¿ã‚’é™¤å¤–ã—ãŸãƒ†ã‚­ã‚¹ãƒˆ
        """
        lines = text.split('\n')
        filtered_lines = []
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            # 1. çŸ­ã™ãã‚‹è¡Œã‚’é™¤å¤–ï¼ˆãŸã ã—è¦‹å‡ºã—ã¯æ®‹ã™ï¼‰
            if len(line) <= 3 and not any(keyword in line for keyword in ["ã€", "ã€‘", "â‘ ", "â‘¡", "â‘¢", "â‘£", "ç¬¬"]):
                continue
            
            # 2. æ•°å€¤ã®ã¿ã€ã¾ãŸã¯æ•°å€¤ãŒéåº¦ã«å¤šã„è¡Œã‚’é™¤å¤–
            numbers = re.findall(r'[\d,ï¼Œ]+', line)
            number_chars = sum(len(num) for num in numbers)
            actual_chars = len(re.sub(r'[\s,ï¼Œ\s]', '', line))
            if actual_chars > 0:
                number_ratio = number_chars / actual_chars
                if number_ratio > 0.4:
                    continue
            
            # 3. æ•°å€¤ã®ç¾…åˆ—ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’é™¤å¤–
            number_sequences = re.findall(r'[\d,ï¼Œ]+(?:\s+[\d,ï¼Œ]+){2,}', line)
            if number_sequences:
                non_number_chars = len(re.sub(r'[\d,ï¼Œ\s]', '', line))
                if non_number_chars < 20:
                    continue
            
            # 4. å˜ä½ã®ã¿ã®è¡Œã‚’é™¤å¤–
            if re.match(r'^[ï¼ˆ(]?å˜ä½[ï¼š:ï¼š]?[ï¼‰)]?', line):
                continue
            
            # 5. æ—¥ä»˜ã®ã¿ã®è¡Œã‚’é™¤å¤–
            if re.match(r'^\d{4}å¹´\d{1,2}æœˆ\d{1,2}æ—¥', line):
                continue
            
            filtered_lines.append(line)
        
        # é‡è¤‡ã™ã‚‹è¡Œã‚’é™¤å»
        seen = set()
        unique_lines = []
        for line in filtered_lines:
            normalized = re.sub(r'\s+', ' ', line.strip())
            if normalized and normalized not in seen and len(normalized) > 3:
                seen.add(normalized)
                unique_lines.append(line)
        
        return '\n'.join(unique_lines)


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    code = "4689"  # ãƒ†ã‚¹ãƒˆå¯¾è±¡ã®éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰
    
    print(f"=" * 60)
    print(f"XBRLãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºãƒ†ã‚¹ãƒˆ - éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰: {code}")
    print(f"=" * 60)
    print()
    
    # 1. EDINETã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–
    print("1. EDINETã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–ä¸­...")
    edinet_client = EdinetAPIClient()
    
    if not edinet_client.api_key:
        print("âŒ EDINET_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return
    
    print("   âœ… EDINETã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–ã«æˆåŠŸã—ã¾ã—ãŸ\n")
    
    # 2. æ›¸é¡ã‚’æ¤œç´¢
    print("2. EDINETã‹ã‚‰æ›¸é¡ã‚’æ¤œç´¢ä¸­...")
    from datetime import datetime
    current_year = datetime.now().year
    years_to_search = [current_year - i for i in range(5)]
    
    # search_documentsãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨
    documents = edinet_client.search_documents(
        code=code,
        years=years_to_search,
        doc_type_code="030",  # æœ‰ä¾¡è¨¼åˆ¸å ±å‘Šæ›¸
        form_code=None  # å…¨æ§˜å¼
    )
    
    if not documents:
        print("âŒ æ›¸é¡ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        return
    
    # æœ€æ–°ã®æ›¸é¡ã‚’å–å¾—
    doc_info = documents[0]
    doc_id = doc_info.get("docID")
    
    print(f"   âœ… æ›¸é¡ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ: {doc_id}")
    print(f"   æ›¸é¡ID: {doc_id}")
    print(f"   æå‡ºæ—¥: {doc_info.get('submitDateTime', 'ä¸æ˜')}")
    print(f"   æ›¸é¡ç¨®åˆ¥: {doc_info.get('docTypeCode', 'ä¸æ˜')}")
    print()
    
    # 3. XBRLã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    print("3. XBRLã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...")
    save_dir = project_root / "reports" / f"{code}_xbrl"
    save_dir.mkdir(parents=True, exist_ok=True)
    
    xbrl_dir = edinet_client.download_document(
        doc_id=doc_id,
        doc_type=1,  # XBRL
        save_dir=save_dir
    )
    
    if not xbrl_dir or not xbrl_dir.exists():
        print("âŒ XBRLã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
        return
    
    print(f"   âœ… XBRLãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†: {xbrl_dir}\n")
    
    # 4. XBRLã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º
    print("4. XBRLã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºä¸­...")
    xbrl_parser = XBRLParser()
    extracted_text = xbrl_parser.extract_text_from_xbrl(
        xbrl_dir=xbrl_dir,
        exclude_tables=True
    )
    
    if not extracted_text:
        print("âŒ ãƒ†ã‚­ã‚¹ãƒˆãŒæŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
        return
    
    print(f"   âœ… ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºå®Œäº†: {len(extracted_text)}æ–‡å­—\n")
    
    # 5. çµæœã‚’ä¿å­˜
    output_file = project_root / f"xbrl_text_{code}_{doc_id}.txt"
    with open(output_file, "w", encoding="utf-8") as f:
        f.write(extracted_text)
    
    print("=" * 60)
    print("æŠ½å‡ºçµæœ")
    print("=" * 60)
    print(f"ãƒ†ã‚­ã‚¹ãƒˆé•·: {len(extracted_text)} æ–‡å­—")
    print(f"ä¿å­˜å…ˆ: {output_file}")
    print()
    print("-" * 60)
    print("ãƒ†ã‚­ã‚¹ãƒˆã®æœ€åˆã®2000æ–‡å­—:")
    print("-" * 60)
    print(extracted_text[:2000])
    print()
    print("-" * 60)
    print("ãƒ†ã‚­ã‚¹ãƒˆã®æœ€å¾Œã®2000æ–‡å­—:")
    print("-" * 60)
    print(extracted_text[-2000:])


if __name__ == "__main__":
    main()

